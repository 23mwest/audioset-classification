{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install -U tensorflow\n",
    "#!pip install -U keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "\n",
    "from ibm_botocore.client import Config\n",
    "import ibm_boto3\n",
    "from IPython.display import HTML\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import sys\n",
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "\n",
    "keras.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing The Data\n",
    "In the below cells, we load the data from IBM Cloud into our working notebook directory.\n",
    "We also demonstrate IBM Watson Studio's integration with .csv files and how they can load into a pandas DataFrame seamlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials_eval = {\n",
    "    'IBM_API_KEY_ID': 'Ebo3x0c7qBvPhY--ksGhQQKASTFj4OfZm1oLAHZOYU92',\n",
    "    'IAM_SERVICE_ID': 'iam-ServiceId-bbeb8c1e-9ef9-41df-a342-a0e9aba1ea44',\n",
    "    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT': 'https://iam.ng.bluemix.net/oidc/token',\n",
    "    'BUCKET': 'audiosetclassification-donotdelete-pr-bochd0jdgqiuyn',\n",
    "    'FILE': 'eval.h5'\n",
    "}\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials_model = {\n",
    "    'IBM_API_KEY_ID': 'Ebo3x0c7qBvPhY--ksGhQQKASTFj4OfZm1oLAHZOYU92',\n",
    "    'IAM_SERVICE_ID': 'iam-ServiceId-bbeb8c1e-9ef9-41df-a342-a0e9aba1ea44',\n",
    "    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT': 'https://iam.ng.bluemix.net/oidc/token',\n",
    "    'BUCKET': 'audiosetclassification-donotdelete-pr-bochd0jdgqiuyn',\n",
    "    'FILE': 'final_weights.h5'\n",
    "}\n",
    "def download_file_cos(credentials,local_file_name,key):  \n",
    "    cos = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n",
    "    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n",
    "    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=credentials['ENDPOINT'])\n",
    "    try:\n",
    "        res=cos.download_file(Bucket=credentials['BUCKET'],Key=key,Filename=local_file_name)\n",
    "    except Exception as e:\n",
    "        print(Exception, e)\n",
    "    else:\n",
    "        print('File Downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Downloaded\n",
      "File Downloaded\n",
      "File Downloaded\n"
     ]
    }
   ],
   "source": [
    "#Downloading the files from IBM Cloud to the current directory\n",
    "download_file_cos(credentials_model,'final_weights.h5','final_weights.h5')\n",
    "download_file_cos(credentials_model,'model_final.json','model_final.json')\n",
    "download_file_cos(credentials_eval,'eval.h5','eval.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--4gqARaEJE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--BfvyPmVMo</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--U7joUcTCo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--i-y1v8Hy8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0BIyqJj9ZU</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id  start_time  end_time\n",
       "0  --4gqARaEJE         0.0      10.0\n",
       "1  --BfvyPmVMo        20.0      30.0\n",
       "2  --U7joUcTCo         0.0      10.0\n",
       "3  --i-y1v8Hy8         0.0       9.0\n",
       "4  -0BIyqJj9ZU        30.0      40.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the label indices and YouTube video ID CSV files to Pandas DataFrames\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "client_d249a8db1de240d283a16bd3ddeac094 = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='Ebo3x0c7qBvPhY--ksGhQQKASTFj4OfZm1oLAHZOYU92',\n",
    "    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "body = client_d249a8db1de240d283a16bd3ddeac094.get_object(Bucket='audiosetclassification-donotdelete-pr-bochd0jdgqiuyn',Key='class_labels_indices.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df_data_1 = pd.read_csv(body)\n",
    "df_data_1.head()\n",
    "body = client_d249a8db1de240d283a16bd3ddeac094.get_object(Bucket='audiosetclassification-donotdelete-pr-bochd0jdgqiuyn',Key='eval_segments.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df_data_2 = pd.read_csv(body)\n",
    "df_data_2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the evaluation data and labels to numpy objects\n",
    "def load_data(hdf5_path):\n",
    "    \"\"\"\n",
    "    Loads the data into numpy objects. \n",
    "    Input : Path to data.\n",
    "    Output : Train/Test examples, corresponding labels, corresponding youtube video_id.\n",
    "    \"\"\"\n",
    "    with h5py.File(hdf5_path, 'r') as hf:\n",
    "        x = hf.get('x')\n",
    "        y = hf.get('y')\n",
    "        video_id_list = hf.get('video_id_list')\n",
    "        x = np.array(x)\n",
    "        y = list(y)\n",
    "        video_id_list = list(video_id_list)\n",
    "        \n",
    "    return x, y, video_id_list\n",
    "\n",
    "def uint8_to_float32(x):\n",
    "    return (np.float32(x) - 128.) / 128.\n",
    "    \n",
    "def bool_to_float32(y):\n",
    "    return np.float32(y)\n",
    "\n",
    "(x, y, video_id_list) = load_data('eval.h5')\n",
    "x = uint8_to_float32(x)\t\t# shape: (N, 10, 128)\n",
    "y = bool_to_float32(y)\t\t# shape: (N, 527)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model\n",
    "In the below cells we build the model and load the weights pre-trained on IBM cloud/dlaas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10, 128)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10, 1024)     132096      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 10, 1024)     4096        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 1024)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10, 1024)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10, 1024)     1049600     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 10, 1024)     4096        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 1024)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 10, 1024)     0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10, 1024)     1049600     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 10, 1024)     4096        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 1024)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 10, 1024)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10, 527)      540175      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10, 527)      540175      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10, 527)      540175      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10, 527)      540175      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 527)          0           dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 527)          0           dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1054)         0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 527)          555985      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 527)          0           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,960,269\n",
      "Trainable params: 4,954,125\n",
      "Non-trainable params: 6,144\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Building the model\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import (Input, Dense, BatchNormalization, Dropout, Lambda,\n",
    "                          Activation, Concatenate)\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "try:\n",
    "    import cPickle\n",
    "except BaseException:\n",
    "    import _pickle as cPickle\n",
    "\n",
    "\n",
    "def average_pooling(inputs, **kwargs):\n",
    "    input = inputs[0]   # (batch_size, time_steps, freq_bins)\n",
    "    return K.mean(input, axis=1)\n",
    "\n",
    "\n",
    "def max_pooling(inputs, **kwargs):\n",
    "    input = inputs[0]   # (batch_size, time_steps, freq_bins)\n",
    "    return K.max(input, axis=1)\n",
    "\n",
    "\n",
    "def attention_pooling(inputs, **kwargs):\n",
    "    [out, att] = inputs\n",
    "\n",
    "    epsilon = 1e-7\n",
    "    att = K.clip(att, epsilon, 1. - epsilon)\n",
    "    normalized_att = att / K.sum(att, axis=1)[:, None, :]\n",
    "\n",
    "    return K.sum(out * normalized_att, axis=1)\n",
    "\n",
    "\n",
    "def pooling_shape(input_shape):\n",
    "\n",
    "    if isinstance(input_shape, list):\n",
    "        (sample_num, time_steps, freq_bins) = input_shape[0]\n",
    "\n",
    "    else:\n",
    "        (sample_num, time_steps, freq_bins) = input_shape\n",
    "\n",
    "    return (sample_num, freq_bins)\n",
    "\n",
    "model_type = 'decision_level_multi_attention'\n",
    "time_steps = 10\n",
    "freq_bins = 128\n",
    "classes_num = 527\n",
    "\n",
    "# Hyper parameters\n",
    "hidden_units = 1024\n",
    "drop_rate = 0.5\n",
    "batch_size = 500\n",
    "\n",
    "# Embedded layers\n",
    "input_layer = Input(shape=(time_steps, freq_bins))\n",
    "\n",
    "a1 = Dense(hidden_units)(input_layer)\n",
    "a1 = BatchNormalization()(a1)\n",
    "a1 = Activation('relu')(a1)\n",
    "a1 = Dropout(drop_rate)(a1)\n",
    "\n",
    "a2 = Dense(hidden_units)(a1)\n",
    "a2 = BatchNormalization()(a2)\n",
    "a2 = Activation('relu')(a2)\n",
    "a2 = Dropout(drop_rate)(a2)\n",
    "\n",
    "a3 = Dense(hidden_units)(a2)\n",
    "a3 = BatchNormalization()(a3)\n",
    "a3 = Activation('relu')(a3)\n",
    "a3 = Dropout(drop_rate)(a3)\n",
    "\n",
    "# Pooling layers\n",
    "if model_type == 'decision_level_max_pooling':\n",
    "    '''Global max pooling.\n",
    "\n",
    "    [1] Choi, Keunwoo, et al. \"Automatic tagging using deep convolutional \n",
    "    neural networks.\" arXiv preprint arXiv:1606.00298 (2016).\n",
    "    '''\n",
    "    cla = Dense(classes_num, activation='sigmoid')(a3)\n",
    "    output_layer = Lambda(max_pooling, output_shape=pooling_shape)([cla])\n",
    "\n",
    "elif model_type == 'decision_level_average_pooling':\n",
    "    '''Global average pooling.\n",
    "\n",
    "    [2] Lin, Min, et al. Qiang Chen, and Shuicheng Yan. \"Network in \n",
    "    network.\" arXiv preprint arXiv:1312.4400 (2013).\n",
    "    '''\n",
    "    cla = Dense(classes_num, activation='sigmoid')(a3)\n",
    "    output_layer = Lambda(\n",
    "        average_pooling,\n",
    "        output_shape=pooling_shape)(\n",
    "        [cla])\n",
    "\n",
    "elif model_type == 'decision_level_single_attention':\n",
    "    '''Decision level single attention pooling.\n",
    "\n",
    "    [3] Kong, Qiuqiang, et al. \"Audio Set classification with attention\n",
    "    model: A probabilistic perspective.\" arXiv preprint arXiv:1711.00927\n",
    "    (2017).\n",
    "    '''\n",
    "    cla = Dense(classes_num, activation='sigmoid')(a3)\n",
    "    att = Dense(classes_num, activation='softmax')(a3)\n",
    "    output_layer = Lambda(\n",
    "        attention_pooling, output_shape=pooling_shape)([cla, att])\n",
    "\n",
    "elif model_type == 'decision_level_multi_attention':\n",
    "    '''Decision level multi attention pooling.\n",
    "\n",
    "    [4] Yu, Changsong, et al. \"Multi-level Attention Model for Weakly\n",
    "    Supervised Audio Classification.\" arXiv preprint arXiv:1803.02353\n",
    "    (2018).\n",
    "    '''\n",
    "    cla1 = Dense(classes_num, activation='sigmoid')(a2)\n",
    "    att1 = Dense(classes_num, activation='softmax')(a2)\n",
    "    out1 = Lambda(\n",
    "        attention_pooling, output_shape=pooling_shape)([cla1, att1])\n",
    "\n",
    "    cla2 = Dense(classes_num, activation='sigmoid')(a3)\n",
    "    att2 = Dense(classes_num, activation='softmax')(a3)\n",
    "    out2 = Lambda(\n",
    "        attention_pooling, output_shape=pooling_shape)([cla2, att2])\n",
    "\n",
    "    b1 = Concatenate(axis=-1)([out1, out2])\n",
    "    b1 = Dense(classes_num)(b1)\n",
    "    output_layer = Activation('sigmoid')(b1)\n",
    "\n",
    "elif model_type == 'feature_level_attention':\n",
    "    '''Feature level attention.\n",
    "\n",
    "    [1] To be appear.\n",
    "    '''\n",
    "    cla = Dense(hidden_units, activation='linear')(a3)\n",
    "    att = Dense(hidden_units, activation='sigmoid')(a3)\n",
    "    b1 = Lambda(\n",
    "        attention_pooling, output_shape=pooling_shape)([cla, att])\n",
    "\n",
    "    b1 = BatchNormalization()(b1)\n",
    "    b1 = Activation(activation='relu')(b1)\n",
    "    b1 = Dropout(drop_rate)(b1)\n",
    "\n",
    "    output_layer = Dense(classes_num, activation='sigmoid')(b1)\n",
    "\n",
    "else:\n",
    "    raise Exception(\"Incorrect model_type!\")\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading weights\n",
    "model.load_weights(\"final_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo supporting code \n",
    "This is the supporting code to run the demo at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(v):\n",
    "    \"\"\"\n",
    "    A function to demonstrate the audio classification.\n",
    "    Input : a random number to retrieve a query video.\n",
    "    Output : video embed string for the YouTube video.\n",
    "    Prints : Top 5 class probabilities from the classifier.\n",
    "    \"\"\"\n",
    "    test_data = x[v:v+1,:,:]\n",
    "    current_infer = model.predict(test_data)\n",
    "    current_video = str(video_id_list[v],'utf-8')\n",
    "    start_time = int(df_data_2.loc[df_data_2['video_id'] == current_video]['start_time'])\n",
    "    video_string = '<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/'+current_video+'?autoplay=1&start='+str(start_time)+';autoplay=1 frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>'\n",
    "    print('Predicted Labels :\\n')\n",
    "    print(df_data_1.loc[current_infer[0].argsort()[-5:][::-1]]['display_name'])\n",
    "    #print('Ground Truth Labels :\\n')\n",
    "    #print(df_data_1.loc[y[v].argsort()[-5:][::-1]]['display_name'])\n",
    "    print(\"Playing video snippet below.. Turn on the speakers..\\n\")\n",
    "    return video_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time Demo\n",
    "\n",
    "Replace the number below to change the video and generate a real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels :\n",
      "\n",
      "401               Foghorn\n",
      "137                 Music\n",
      "152    Keyboard (musical)\n",
      "186           French horn\n",
      "153                 Piano\n",
      "Name: display_name, dtype: object\n",
      "Playing video snippet below.. Turn on the speakers..\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/PYislCydAPQ?autoplay=1&start=30;autoplay=1 frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try out a random number between 0 and 20000 \n",
    "video_number = 9384\n",
    "HTML(demo(video_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse Search Audio using keywords\n",
    "\n",
    "In this section we will first perform inference on the full test dataset and store it to later retrieve search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we get the inference for all our data and store it under `inferences`\n",
    "inferences = model.predict(x[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we write a function to retrieve the required audios\n",
    "def search_audio(keyword, infer=inferences):\n",
    "    \"\"\"\n",
    "    Uses the inferences made using the audioset classifier to lookup and retrieve relevant audio/video for a given keyword.\n",
    "    Inputs : search query, inferences on test dataset.\n",
    "    Outputs : YouTube embed link for the strongest video returned and a list of all videos containing the search query.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        class_id = int(df_data_1.loc[df_data_1['display_name'] == keyword]['index'])\n",
    "        print(\"Retrieving videos containing \"+keyword +\" with the highest probabilities...\")\n",
    "    except:\n",
    "        class_id = -1\n",
    "        print(\"Search Query is invalid!\")\n",
    "    strong_inferences = np.argsort(inferences,axis = 1)[:,-5:]\n",
    "    video_ids = np.where(strong_inferences==class_id)[0]\n",
    "    video_strings = []\n",
    "    max_prob = -1\n",
    "    strongest_video_embed = ''\n",
    "    print_counter = 0\n",
    "    if(video_ids.any()):\n",
    "        print(\"...Done!\")\n",
    "        print(\"Printing a few strong results.. \")\n",
    "    for v in video_ids:\n",
    "        current_video = str(video_id_list[v],'utf-8')\n",
    "        start_time = int(df_data_2.loc[df_data_2['video_id'] == current_video]['start_time'])\n",
    "        video_string = 'https://www.youtube.com/watch?v='+current_video+'&t='+str(start_time)\n",
    "        if(inferences[v][class_id]>0.8 and print_counter<10):\n",
    "            print(video_string + \" contains \"+keyword+\" with probability \"+ str(inferences[v][class_id]))\n",
    "            print_counter +=1\n",
    "        video_strings.append(video_string)\n",
    "        if inferences[v][class_id]>max_prob:\n",
    "            max_prob = inferences[v][class_id]\n",
    "            max_video = current_video\n",
    "            max_time = start_time\n",
    "    if(not video_strings):\n",
    "        print(\"No videos found for the search query: \"+keyword )\n",
    "    else:\n",
    "        strongest_video_embed = '<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/'+max_video+'?autoplay=1&start='+str(max_time)+';autoplay=1 frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>'\n",
    "    return strongest_video_embed,video_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving videos containing Car with the highest probabilities...\n",
      "...Done!\n",
      "Printing a few strong results.. \n",
      "https://www.youtube.com/watch?v=-CZ1LIc8aos&t=20 contains Car with probability 0.863814\n",
      "https://www.youtube.com/watch?v=-Wd5YV97ftU&t=320 contains Car with probability 0.948551\n",
      "https://www.youtube.com/watch?v=1G6wtnmdZhE&t=30 contains Car with probability 0.893657\n",
      "\n",
      " Playing video with the strongest probability of containing Car ..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/-Wd5YV97ftU?autoplay=1&start=320;autoplay=1 frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query = 'Car'\n",
    "embed = search_audio(search_query)[0]\n",
    "if(embed):\n",
    "    print(\"\\n Playing video with the strongest probability of containing \"+search_query+\" ..\")\n",
    "HTML(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
