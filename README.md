# Audio Classification using Keras and Jupyter Notebooks running on IBM Cloud

In this developer code pattern, we first create a Deep Learning model to classify audio embeddings. We train the model on IBM Deep Learning as a Service (DLaaS) platform and then perform inference/evaluation on IBM Watson Studio. 

The model will use audio embeddings generated by the VGG-ish model as an input and generate output probabilities/scores for 527 classes. For the purposes of illustrating the concept and exposing a developer to the features on IBM Cloud platforms, we use Google's Audioset data where the embeddings have been pre-processed and available readily.  However, a developer can leverage this model to create their own custom audio classifier trained on their own audio embeddings/data.

When the reader has completed this Code Pattern, they will understand how to:

    Setup an IBM Cloud object storage bucket and upload the training data to the cloud.
    Upload a Deep Learning model to IBM DLaaS for training.
    Integrate the object storage buckets into IBM Watson Studio.
    Perform inference on an evaluation dataset using Jupyter Notebooks over IBM Watson Studio.

## Training the model

